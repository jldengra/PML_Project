aggregate(weight ~ feed, data = chickwts, mean)
aggregate(weight ~ feed, data = chickwts, mean)
str(ChickWeight)
aggregate(weight ~ DietType, data = ChickWeight, mean)
aggregate(weight ~ DietType, data = ChickWeight, FUN = "mean")
which.max(aggregate(weight ~ DietType, data = ChickWeight, FUN = "mean"))
diets <- aggregate(weight ~ DietType, data = ChickWeight, FUN = "mean")
class(diets)
which.max(diet[,2])
diets[,2]
which.max(diets[,2])
diets[which.max(diets[,2])]
diets[which.max(diets[,2]), ]
diets[which.max(diets[,2]), ]$diettype
diets[which.max(diets[,2]), ]$DietType
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
subset(ChickWeight, Time %in% seq(11, 11, 1)))
subset(ChickWeight, Time %in% seq(11, 11, 1))
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
shiny::runApp('D:/Training/Data Science/JHU Specialization/Developing Data Products/Project')
library(caret)
install.packages(caret)
install.packages("caret")
library(caret)
library(caret)
install.packages("caret")
library(caret)
library(kernlab)
install.packages("kernlab")
library(caret)
library(kernlab)
data(spam)
View(spam)
str(spam)
inTrain <- createDataPartition(y = spam$type,
p = .75, list = FALSE )
inTrain
training <- spam[inTrain,]
-inTrain
testing <- spam[-inTrain, ]
dim(training)
set.seed(32343)
modelFit <- train(type ~ ., data = training, method = "glm")
install.packages("e1071")
modelFit <- train(type ~ ., data = training, method = "glm")
warnings()
modelFit
modelFit$finalModel
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit$finalModel
set.seed(32343)
modelFit <- train(type ~ ., data = training, method = "glm")
modelFit$finalModel
predictions <- predict(modelFit, newdata = testing)
predictions
confusionMatrix(predictions, testing$type)
library(caret)
library(kernlab)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y = spam$type,
p = 0.75, list = FALSE)
install.packages("rCharts")
install.packages("rCharts")
install.packages("rCharts")
install.packages("rCharts")
spam[inTrain, ]
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y = spam$type,
p = 0.75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
inTrain
inTrain
View(inTrain)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y = spam$type,
p = 0.75, list = FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
ibrary(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
prComp$rotation
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
typeColor
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
library(caret)
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$type,predict(modelFit,testing))
t
library(caret);data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,
p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",
xlab="Waiting",ylab="Duration")
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",
xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",
xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",
xlab="Waiting",ylab="Duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
# Calculate RMSE on test
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
par(mfrow=c(1,2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
par(mfrow=c(1,1))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
modFit<- train(wage ~ age + jobclass + education,
method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
plot(finMod$residuals,pch=19)
pred <- predict(modFit, testing)
qplot(wage,pred,colour=year,data=testing)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
library(AppliedPredictiveModeling)
# install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
train
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(train)
View(testing)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
head(training, 10); head(testing, 10)
head(training, 1)
View(training)
View(testing)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
View(testing)
View(training)
View(train)
View(test)
head(test)
head(train)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50) #implicit list = TRUE
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50) #implicit list = TRUE
trainIndex
trainIndex[1]
trainIndex[[1]]
trainIndex[[1]][1]
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
View(trainIndex)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50) #implicit list = TRUE
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(trainIndex)
View(training)
View(testing)
View(testing)
View(testing)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
str(diagnosis)
str(predictors)
diagnosis
str(diagnosis)
str(AlzheimerDisease)
library(AppliedPredictiveModeling)
set.seed(1000)
data(concrete)
library(caret)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training)
plot(finMod$residuals,pch=19)
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
finMod
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
str(training)
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
# Another way
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
str(training)
splitOn <- cut2(training$BlastFurnaceSlag, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
splitOn <- cut2(training$FlyAsh, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
splitOn <- cut2(training$FlyAsh, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
splitOn <- cut2(training$FlyAsh, g=6)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
splitOn <- cut2(training$FlyAsh, g=8)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
splitOn <- cut2(training$FlyAsh, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(concrete)
str(concrete)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(concrete$SuperPlasticizer)
str(concrete$SuperPlasticizer)
str(concrete$Superplasticizer)
hist(concrete$Superplasticizer)
summary(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer + 1))
hist(concrete$Superplasticizer)
library(caret)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predictorNames <- names(training)
predictorNames
predictorNamesIL <-  predictorNames[substr(predictorNames, 1, 2) == "IL"]
predictorNamesIL
training[, predictorNamesIL]
pca <- preProcess(training[, predictorNamesIL], method = "pca", thresh = .80)
pca
pca$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[, c(ILpredictor, "diagnosis")]
trainingIL <- training[, c(predictorNamesIL, "diagnosis")]
testingIL <- testing[, c(predictorNamesIL, "diagnosis")]
ModelAll <- train(diagnosis ~ ., data = trainingIL, method = "glm")
confusionMatrix(testingIL$diagnosis, predict(ModelAll, testingIL))
preProc <- preProcess(training[, predictorNamesIL], method = "pca", thresh = .8)
trainPC <- predict(preProc, training[, predictorNamesIL])
ModelPCA <- train(trainingIL$diagnosis ~ ., method = "glm", data = trainPC)
testPC <- predict(preProc, testing[, predictorNamesIL])
confusionMatrix(testingIL$diagnosis, predict(ModelPCA, testPC))
setwd("D:/Training/Data Science/JHU Specialization/Practical Machine Learning/Project/PML_Project")
training <- read.csv("./data/pml-training.csv")
testing  <- read.csv("./data/pml-testing.csv")
str(training$classe)
summary(training$classe)
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
testing  <- read.csv("./data/pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))
rm(ls())
ls()
rm(ls())
rm(list = ls())
setwd("D:/Training/Data Science/JHU Specialization/Practical Machine Learning/Project/PML_Project")
training <- read.csv("./data/pml-training.csv")
testing  <- read.csv("./data/pml-testing.csv")
str(training$classe)
summary(training$classe)
training <- read.csv("./data/pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
testing  <- read.csv("./data/pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))
training <- training [ , -(1:7)]
checkWithoutNAs <- sapply(training, function(x)all(!is.na(x)))
variablesWithoutNAs <- names(checkWithoutNAs)[names(checkWithoutNAs) %in% names(checkWithoutNAs)[checkWithoutNAs]]
training <- training[ , variablesWithoutNAs]
library(caret)
variablesWithNearZeroVar <- nearZeroVar(training)
if (length(variablesWithNearZeroVar) > 0)
training <- training[ , -variablesWithNearZeroVar]
inTrain  <- createDataPartition(training$classe, p = 3/4, list = FALSE)
trainData <- training[ inTrain, ]
testData  <- training[ -inTrain, ]
set.seed(201601)
modelCART <- train(classe ~ ., data = trainData, method = "rpart")
library(rattle)
fancyRpartPlot(modelCART$finalModel, sub = " Classification and Regression Tree (CART) model")
fancyRpartPlot(modelCART$finalModel, sub = " Classification and Regression Tree (CART) model")
predictionCART <- predict(modelCART, testData, type = "class")
predictionsA1 <- predict(modFitA1, myTesting)
predictionCART <- predict(modelCART, testData, type = "class")
predictionCART <- predict(modelCART, testData)
confusionMatrix(predictionCART, testData$classe)
predictionCART <- predict(modelCART, trainData)
confusionMatrix(predictionCART, trainData$classe)
predictionCART <- predict(modelCART, testData)
confusionMatrix(predictionCART, testData$classe)
predict(modelCART, testData)
modelCART <- rpart(classe ~ ., data = trainData, method="class")
predictionCART <- predict(modelCART, testData)
confusionMatrix(predictionCART, testData$classe)
predictionCART <- predict(modelCART, testData)
confusionMatrix(predictionCART, testData$classe)
predict(modelCART, testData)
fancyRpartPlot(modelCART)
fancyRpartPlot(modelCART, sub = " Classification and Regression Tree (CART) model"))
fancyRpartPlot(modelCART, sub = " Classification and Regression Tree (CART) model")
predictionCART <- predict(modelCART, testData, type = "class")
confusionMatrix(predictionCART, testData$classe)
set.seed(201601)
modelLDA <- train(classe ~ ., data = trainData, method = "lda")
predictionLDA <- predict(modelLDA, testData)
confusionMatrix(predictionLDA, testData$classe)
modelLDA <- lda(classe ~ ., data = trainData)
predictionLDA <- predict(modelLDA, testData)
confusionMatrix(predictionLDA, testData$classe)
table(predict(modelLDA, type="class")$class, estData$classe)
table(predict(modelLDA, type="class")$class, testData$classe)
(predict(modelLDA, type="class")
)
predictionLDA <- predict(modelLDA, testData, type = "class")
str(predictoLDA)
str(predictionLDA)
table(predictionLDA$class, testData$classe)
confusionMatrix(predictionLDA$class, testData$classe)
if (!"MASS" %in% installed.packages()[ , 1]) { install.packages("MASS") }
set.seed(201601)
modelLDA <- train(classe ~ ., data = trainData, method = "lda")
set.seed(201601)
# modelLDA <- train(classe ~ ., data = trainData, method = "lda")
# predictionLDA <- predict(modelLDA, testData)
# confusionMatrix(predictionLDA, testData$classe)
library(MASS)
modelLDA <- lda(classe ~ ., data = trainData)
predictionLDA <- predict(modelLDA, testData, type = "class")
str(predictionLDA)
# Confusion matrix
table(predictionLDA$class, testData$classe)
confusionMatrix(predictionLDA$class, testData$classe)
if (!"randomForest" %in% installed.packages()[ , 1]) { install.packages("randomForest") }
set.seed(201601)
library(randomForest)
modelRF <- randomForest(y ~ ., data = trainData, importance = FALSE)
modelRF <- randomForest(classe ~ ., data = trainData, importance = FALSE)
predictionRF <- predict(modelRF, testData)
predictionRF <- predict(modelRF, testData)
confusionMatrix(predictionRF, testData$classe)
confusionMatrix(predictionCART, testData$classe)$overall[1]
confusionMatrix(predictionLDA$class, testData$classe)
confusionMatrix(predictionRF, testData$classe)
prediction <- predict(modelRF, testing)
prediction
fancyRpartPlot(modelCART, sub = "Classification and Regression Tree (CART) model")
fancyRpartPlot(modelCART, sub = "Classification and Regression Tree (CART) model",
cex = 0.45)
fancyRpartPlot(modelCART, sub = "Classification and Regression Tree (CART) model",
cex = 0.6)
fancyRpartPlot(modelCART, sub = "Classification and Regression Tree (CART) model",
cex = 0.5)
